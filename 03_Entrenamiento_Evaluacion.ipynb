{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import pickle\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_train = pd.read_csv(r'C:\\Users\\Sengan\\Desktop\\prestamo acciones\\Proyecto-ML\\Train_data\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos_train[['Share pledge ratio of controlling shareholders',\n",
    "        'Pledge ratio of unlimited shares',\n",
    "        'audit opinion ',\n",
    "        'Downgrade or negative',\n",
    "        'Ratio of other receivables to total assets',\n",
    "        'ROA',\n",
    "        'Asset liability ratio (total liabilities - contract liabilities - advance receipts)/(total assets - goodwill - contract liabilities - advance receipts)',\n",
    "        'Pledge ratio of limited sale shares',\n",
    "        'ROE',\n",
    "        'Enterprise age']]\n",
    "y = datos_train['IsDefault']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average='binary', zero_division=1),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average='binary', zero_division=1),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred, average='binary', zero_division=1),\n",
    "        \"ROC AUC\": roc_auc_score(y_true, y_pred),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Regresión Logística\n",
    "model_1 = LogisticRegression(C= 10, penalty='l2', random_state=42)\n",
    "model_1.fit(X_train_scaled, y_train)\n",
    "y_pred_logistic = model_1.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_logistic, \"Logistic Regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SVM Lineal\n",
    "model_2 = SVC(C= 1 , kernel='linear', random_state=42)\n",
    "model_2.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = model_2.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_svm, \"Linear SVM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. KNN\n",
    "model_3 = KNeighborsClassifier(n_neighbors=5, weights= 'distance')\n",
    "model_3.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = model_3.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_knn, \"KNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Random Forest\n",
    "model_4 = RandomForestClassifier(max_depth= None ,n_estimators=100, random_state=42)\n",
    "model4.fit(X_train, y_train)  # No necesita escalado\n",
    "y_pred_rf = model4.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_rf, \"Random Forest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:15:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#5. XGBoost\n",
    "model_5 = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_5.fit(X_train, y_train)  # No necesita escalado\n",
    "y_pred_xgb = model_5.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_xgb, \"XGBoost\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5911 - loss: 0.6445 - val_accuracy: 0.8261 - val_loss: 0.4159\n",
      "Epoch 2/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.3663 - val_accuracy: 0.8424 - val_loss: 0.3371\n",
      "Epoch 3/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8658 - loss: 0.3200 - val_accuracy: 0.8533 - val_loss: 0.3138\n",
      "Epoch 4/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2559 - val_accuracy: 0.8533 - val_loss: 0.3024\n",
      "Epoch 5/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2524 - val_accuracy: 0.8750 - val_loss: 0.2943\n",
      "Epoch 6/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 0.2215 - val_accuracy: 0.8804 - val_loss: 0.2906\n",
      "Epoch 7/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2164 - val_accuracy: 0.9022 - val_loss: 0.2859\n",
      "Epoch 8/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8785 - loss: 0.2784 - val_accuracy: 0.8641 - val_loss: 0.2869\n",
      "Epoch 9/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2545 - val_accuracy: 0.8859 - val_loss: 0.2823\n",
      "Epoch 10/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9037 - loss: 0.2442 - val_accuracy: 0.9076 - val_loss: 0.2798\n",
      "Epoch 11/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9178 - loss: 0.2485 - val_accuracy: 0.9076 - val_loss: 0.2802\n",
      "Epoch 12/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2431 - val_accuracy: 0.8804 - val_loss: 0.2800\n",
      "Epoch 13/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9096 - loss: 0.2347 - val_accuracy: 0.9022 - val_loss: 0.2741\n",
      "Epoch 14/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9131 - loss: 0.2342 - val_accuracy: 0.8859 - val_loss: 0.2804\n",
      "Epoch 15/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8897 - loss: 0.2482 - val_accuracy: 0.9185 - val_loss: 0.2693\n",
      "Epoch 16/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2219 - val_accuracy: 0.9076 - val_loss: 0.2699\n",
      "Epoch 17/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9107 - loss: 0.2032 - val_accuracy: 0.9076 - val_loss: 0.2691\n",
      "Epoch 18/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2135 - val_accuracy: 0.9076 - val_loss: 0.2656\n",
      "Epoch 19/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2373 - val_accuracy: 0.8967 - val_loss: 0.2680\n",
      "Epoch 20/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9225 - loss: 0.2122 - val_accuracy: 0.8804 - val_loss: 0.2803\n",
      "Epoch 21/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2472 - val_accuracy: 0.8859 - val_loss: 0.2817\n",
      "Epoch 22/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9027 - loss: 0.2644 - val_accuracy: 0.9076 - val_loss: 0.2642\n",
      "Epoch 23/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.1945 - val_accuracy: 0.9022 - val_loss: 0.2632\n",
      "Epoch 24/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2160 - val_accuracy: 0.9022 - val_loss: 0.2689\n",
      "Epoch 25/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.2196 - val_accuracy: 0.8859 - val_loss: 0.2750\n",
      "Epoch 26/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9134 - loss: 0.2098 - val_accuracy: 0.9076 - val_loss: 0.2667\n",
      "Epoch 27/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.1892 - val_accuracy: 0.8859 - val_loss: 0.2866\n",
      "Epoch 28/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2059 - val_accuracy: 0.8913 - val_loss: 0.2823\n",
      "Epoch 29/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9173 - loss: 0.2067 - val_accuracy: 0.9022 - val_loss: 0.2641\n",
      "Epoch 30/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9214 - loss: 0.2236 - val_accuracy: 0.9022 - val_loss: 0.2663\n",
      "Epoch 31/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.1986 - val_accuracy: 0.8913 - val_loss: 0.2818\n",
      "Epoch 32/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9278 - loss: 0.2035 - val_accuracy: 0.8967 - val_loss: 0.2908\n",
      "Epoch 33/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9429 - loss: 0.1711 - val_accuracy: 0.9076 - val_loss: 0.2695\n",
      "Epoch 34/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9466 - loss: 0.1584 - val_accuracy: 0.8913 - val_loss: 0.2863\n",
      "Epoch 35/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2002 - val_accuracy: 0.9022 - val_loss: 0.2789\n",
      "Epoch 36/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1817 - val_accuracy: 0.9022 - val_loss: 0.2750\n",
      "Epoch 37/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.1449 - val_accuracy: 0.9022 - val_loss: 0.2804\n",
      "Epoch 38/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1751 - val_accuracy: 0.9076 - val_loss: 0.2790\n",
      "Epoch 39/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9331 - loss: 0.2022 - val_accuracy: 0.9076 - val_loss: 0.2794\n",
      "Epoch 40/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1748 - val_accuracy: 0.9022 - val_loss: 0.2776\n",
      "Epoch 41/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9350 - loss: 0.1753 - val_accuracy: 0.8967 - val_loss: 0.2848\n",
      "Epoch 42/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1844 - val_accuracy: 0.9076 - val_loss: 0.2847\n",
      "Epoch 43/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.1658 - val_accuracy: 0.8967 - val_loss: 0.2963\n",
      "Epoch 44/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9360 - loss: 0.1711 - val_accuracy: 0.9076 - val_loss: 0.2962\n",
      "Epoch 45/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1799 - val_accuracy: 0.9076 - val_loss: 0.2895\n",
      "Epoch 46/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1639 - val_accuracy: 0.8967 - val_loss: 0.3021\n",
      "Epoch 47/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9518 - loss: 0.1418 - val_accuracy: 0.9022 - val_loss: 0.2988\n",
      "Epoch 48/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.1641 - val_accuracy: 0.9022 - val_loss: 0.3083\n",
      "Epoch 49/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1564 - val_accuracy: 0.8913 - val_loss: 0.2991\n",
      "Epoch 50/50\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9448 - loss: 0.1442 - val_accuracy: 0.8967 - val_loss: 0.2923\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "# 6. Red Neuronal (MLP)\n",
    "model_6 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Capa oculta 1\n",
    "    Dense(32, activation='relu'),  # Capa oculta 2\n",
    "    Dense(1, activation='sigmoid')  # Capa de salida\n",
    "])\n",
    "\n",
    "model_6.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model_6.fit(X_train_scaled, y_train, \n",
    "                    epochs=50, \n",
    "                    batch_size=16, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1)\n",
    "\n",
    "model_6.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "y_pred_keras = (model_6.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "results.append(evaluate_model(y_test, y_pred_keras, \"Neural Network (Keras)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy  Precision    Recall  F1-Score   ROC AUC\n",
      "4                 XGBoost  0.878261   0.696970  0.560976  0.621622  0.754033\n",
      "0     Logistic Regression  0.873913   0.714286  0.487805  0.579710  0.722738\n",
      "1              Linear SVM  0.865217   0.692308  0.439024  0.537313  0.698348\n",
      "6  Neural Network (Keras)  0.860870   0.666667  0.439024  0.529412  0.695703\n",
      "3           Random Forest  0.856522   0.625000  0.487805  0.547945  0.712156\n",
      "5  Neural Network (Keras)  0.856522   0.642857  0.439024  0.521739  0.693057\n",
      "2                     KNN  0.834783   0.551724  0.390244  0.457143  0.660730\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by=\"Accuracy\", ascending=False, inplace=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Best Params  Best F1-Score  \\\n",
      "model_1                         {'C': 10, 'penalty': 'l2'}       0.648476   \n",
      "model_2                       {'C': 1, 'kernel': 'linear'}       0.612379   \n",
      "model_3          {'n_neighbors': 5, 'weights': 'distance'}       0.566287   \n",
      "model_4  {'max_depth': None, 'min_samples_split': 2, 'n...       0.668515   \n",
      "model_5  {'learning_rate': 0.2, 'max_depth': 3, 'n_esti...       0.715209   \n",
      "\n",
      "                                    best_estimator  \n",
      "model_1  LogisticRegression(C=10, random_state=42)  \n",
      "model_2  LogisticRegression(C=10, random_state=42)  \n",
      "model_3  LogisticRegression(C=10, random_state=42)  \n",
      "model_4  LogisticRegression(C=10, random_state=42)  \n",
      "model_5  LogisticRegression(C=10, random_state=42)  \n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar los mejores modelos y resultados\n",
    "best_models = {}\n",
    "\n",
    "# 1. GridSearch para Regresión Logística\n",
    "param_grid_logistic = {'C': [0.1, 1, 10, 100], 'penalty': ['l2']}\n",
    "grid_logistic = GridSearchCV(LogisticRegression(random_state=42), param_grid_logistic, cv=5, scoring='f1')\n",
    "grid_logistic.fit(X_train_scaled, y_train)\n",
    "best_models[\"model_1\"] = grid_logistic.best_params_, grid_logistic.best_score_, grid_logistic.best_estimator_\n",
    "\n",
    "# 2. GridSearch para SVM Lineal\n",
    "param_grid_svm = {'C': [0.1, 1, 10, 100], 'kernel': ['linear']}\n",
    "grid_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5, scoring='f1')\n",
    "grid_svm.fit(X_train_scaled, y_train)\n",
    "best_models[\"model_2\"] = grid_svm.best_params_, grid_svm.best_score_, grid_logistic.best_estimator_\n",
    "\n",
    "\n",
    "# 3. GridSearch para KNN\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='f1')\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "best_models[\"model_3\"] = grid_knn.best_params_, grid_knn.best_score_, grid_logistic.best_estimator_\n",
    "\n",
    "\n",
    "# 4. GridSearch para Random Forest\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='f1')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_models[\"model_4\"] = grid_rf.best_params_, grid_rf.best_score_, grid_logistic.best_estimator_\n",
    "\n",
    "\n",
    "# 5. GridSearch para XGBoost\n",
    "param_grid_xgb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 10]}\n",
    "grid_xgb = GridSearchCV(xgb.XGBClassifier(eval_metric='logloss', random_state=42), param_grid_xgb, cv=5, scoring='f1')\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_models[\"model_5\"] = grid_xgb.best_params_, grid_xgb.best_score_, grid_logistic.best_estimator_\n",
    "\n",
    "\n",
    "# Mostrar los mejores hiperparámetros y puntajes\n",
    "import pandas as pd\n",
    "best_models_df = pd.DataFrame.from_dict(best_models, orient='index', columns=['Best Params', 'Best F1-Score', 'best_estimator'])\n",
    "print(best_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 199, in _get_response_values\n",
      "    classes = estimator.classes_\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'KerasGridSearch' object has no attribute 'classes_'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sengan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for Neural Network: {'batch_size': 16, 'epochs': 50, 'learning_rate': 0.001, 'neurons': 32}\n",
      "Best F1-Score for Neural Network: nan\n",
      "Best Model Estimatid KerasGridSearch(batch_size=16, neurons=32)\n"
     ]
    }
   ],
   "source": [
    "class KerasGridSearch(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.001, neurons=64, batch_size=32, epochs=50, verbose=0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.neurons = neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        self.model_ = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(self.neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "            Dense(int(self.neurons / 2), activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model_ = self.build_model()\n",
    "        self.model_.fit(X, y, batch_size=self.batch_size, epochs=self.epochs, verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.model_.predict(X)\n",
    "        return (predictions > 0.5).astype(int)\n",
    "\n",
    "# Definir espacio de búsqueda\n",
    "param_grid_keras = {\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'neurons': [32, 64, 128],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [50, 100]\n",
    "}\n",
    "\n",
    "# Integrar con GridSearchCV\n",
    "keras_grid = GridSearchCV(KerasGridSearch(verbose=0), param_grid_keras, cv=3, scoring='f1')\n",
    "keras_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros y puntaje\n",
    "print(\"Best Params for Neural Network:\", keras_grid.best_params_)\n",
    "print(\"Best F1-Score for Neural Network:\", keras_grid.best_score_)\n",
    "print(\"Best Model Estimatid\", keras_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_modelos(modelos):\n",
    "    for i, (key, value) in enumerate(modelos.items(), start=1):\n",
    "        file_name = f\"model_{i}.pkl\"\n",
    "        with open(file_name, 'wb') as file:\n",
    "            pickle.dump(value[2], file)\n",
    "    print(f\"Se han guardado {len(modelos)} modelos exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = grid_xgb.best_estimator_  \n",
    "\n",
    "with open('modelo_final_xgboost.pkl', 'wb') as file:\n",
    "    pickle.dump(modelo_final, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "with open('keras_grid_search.pkl', 'wb') as file:\n",
    "    pickle.dump(keras_grid.best_estimator_, file)\n",
    "\n",
    "# Guardar el modelo Keras subyacente\n",
    "best_model_keras = keras_grid.best_estimator_.model_\n",
    "best_model_keras.save('best_keras_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final_config = modelo_final.get_params()\n",
    "\n",
    "# Guardar la configuración del modelo en un archivo YAML\n",
    "config_file_name = 'model_config.yaml'\n",
    "with open(config_file_name, 'w') as file:\n",
    "    yaml.dump(modelo_final_config, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
